{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Description\n\n>    Introduction: The main objective of this notebook is to classify the White Blood Cell (WBC) components.There are 5 main components. They are: Eoisinophil, Lymphocyte, Monocyte, Neutrophil and Basophil. Here we have classified only among the 4 classes except Basophil due to very small number of it's data. Here we have used \"rmsprop\" optimizer and the output layer is of 4 nodes as it is to classify into 4 classes and the \"softmax\" activation function is used.\n\n\n> Import Libraries:  The required library functions has been imported. We are using keras model with Tensorflow backend. The sklearn library is imported for generating the confusion matrix."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.models import load_model\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport os\nimport shutil\nfrom keras import backend as K\nimport random\nimport glob\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Declaration: At first the image size is declared in which we will train our model and then the path to our dataset is declared. In each of the train, validation and test folders there are 4 sub-folders with the names of the classes and in those sub-folders the data resides. Total number of training sample is 9957, validation sample is 1887 and test sample is 600. "},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 120, 160\n\ntrain_data_dir = '../input/main-dataset/main_dataset/train'\nvalidation_data_dir = '../input/main-dataset/main_dataset/validation'\ntest_data_dir = '../input/main-dataset/main_dataset/test'\nnb_train_samples = 9957\nnb_validation_samples = 1887\nepochs = 30\nbatch_size = 32\n#regularizer = tf.keras.regularizers.l2(0.01,)\n\nif K.image_data_format() == 'channels_first':\n  input_shape = (3, img_width, img_height)\nelse:\n  input_shape = (img_width, img_height, 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Data Generator: We have used the ImageDataGenerator function to augment our dataset. This is done so that at every epoch the model faces a different version of the same data. It really increases the probability of learning features accurately. You csn check more about ImageDataGenerator here [ImageDataGenerator](https://keras.io/api/preprocessing/image/). We have only rescaled the test generator because we don't need to augment our validation(data set unseen to the model which is used to validate the model or to check how well it will perform on real world data.) or test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale = 1./255,\n    shear_range = 0.3,\n    zoom_range = 0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Batches of data: Using the data generator now the train, validation and test data batches is created on which we will train our model, validate our model and find out the test accuracy respectively. Class mode is used \"categorical\" because this is a categorical classification. Here the flow from directory method is used which will extract the data from the directory we defined in our Declarion section. You can learn more about it from [flow_from_directory](https://keras.io/api/preprocessing/image/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_batches = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size = (img_width, img_height),\n    batch_size = batch_size,\n    #classes=['EOISINOPHIL', 'LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL'],\n    class_mode = 'categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_batches = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size = (img_width, img_height),\n    batch_size = batch_size,\n    #color_mode = 'grayscale',\n    class_mode = 'categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_batches = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size = (img_width, img_height),\n    batch_size = 600,\n    #color_mode = 'grayscale',\n    class_mode = 'categorical')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Plotting Image and Labels: This is just a function used to plot the images along with there labels just to demonstrate hoe it looks. Nothing to modify here. You can directly copy and paste it"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plots(ims, figsize=(12,6), rows=None, interp=False, titles=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != 3):\n            ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows +1\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, cols, i+1)\n        sp.axis('Off')\n        if titles is not None:\n            sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Extracting labels: In this section the images and their labels are extracted. The next function takes the train_batches as input and stores the image and labels into \"imgs\" and \"labels\" variable respectively. It takes a number of samples equal to the batch_size declared in the train_batches. \"*This is just to demostrate,nothing to do with the training*\""},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs, labels = next(train_batches)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Don't be frustrated if the image and label output is black or overlapped. It is because the batch_size is huge and here all those images can't be shown in a organized way."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Eoisinophil=8[1.0.0.0],Lymphocyte=4[0.1.0.0],monocyte=2[0.0.1.0],neutrophil=1[0.0.0.1]-->Labels\nplots(imgs, rows=4, titles=labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model\n\n> Here our model is created. We have used Sequential model. We have used some Convolutinal layer followed by normalization maxpooling and dropout. Initially the input shape is neede to be declared explicitly but then the layers take input of size whatever it's previous layer's output size is."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=input_shape, activation='relu', padding='same'))\n#model.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n#model.add(BatchNormalization())\n#model.add(Activation('relu'))\n#model.add(MaxPooling2D(pool_size=(2, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n#model.add(BatchNormalization())\n#model.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n#model.add(BatchNormalization())\n#model.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n#model.add(BatchNormalization())\n#model.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(4))\nmodel.add(Activation('softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Compilation: We compiled the model using rmsprop optimizer. The metrics is something on which the perfomance is measured and in this case it is the accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training:\n\n> The fit generator function is used here on the model. First the name is specified where the training datset is, then validation_data holds the valid_batches on which model validation is performed. Then a callback function which mainly monitors the training and stops the training when the monitoring variable doesn't do well and also has a patience value which means how long it will wait until stops the training. Then the model is saved in the specified directory."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nh = model.fit_generator(\n    train_batches,\n    steps_per_epoch = nb_train_samples // batch_size,\n    epochs = epochs,\n    validation_data = valid_batches,\n    validation_steps = nb_validation_samples // batch_size,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5),\n        tf.keras.callbacks.ModelCheckpoint(filepath = '/kaggle/working/model_{val_accuracy:.3f}.h5', save_best_only=True,\n                                          save_weights_only=False, monitor='val_accuracy')\n    ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Don't be frustrated if the image or labels output is black or overlapped. It is because the batch_size is huge and here all those images can't be shown in a organized way."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imgs, test_labels = next(test_batches)\nplots(test_imgs, rows=10, titles=test_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> This is done because in the upcoming section it will be neede because the confusion matrix takes input as single value(like: 1 or 2 ). "},{"metadata":{"trusted":true},"cell_type":"code","source":"rounded_labels = np.argmax(test_labels, axis=-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Load Model: Here the best performing model is loaded."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_model = load_model('./model_0.887.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction:\n\n> Prediction is done using the best performing model on the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = test_model.predict_generator(test_batches, steps=1, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> This is done because in the upcoming section it will be neede because the confusion matrix takes input as single value(like: 1 or 2 ). "},{"metadata":{"trusted":true},"cell_type":"code","source":"rounded_prediction = np.argmax(predictions, axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in rounded_prediction:\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confusion matrix:\n\n>In the confusin_matrix function there are two parameters. One is the true labels that has been loaded previously and the predicted labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_true=rounded_labels, y_pred=rounded_prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> This function is just copied and you can use it directly without any modification"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"black\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> It's the confusion matrix which illustrates how well your model performs on test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_plot_labels = ['EOISINOPHIL', 'LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL']\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='confusion_matrix')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"accs = h.history['accuracy']\nval_accs = h.history['val_accuracy']\n\nplt.plot(range(len(accs)),accs, label = 'Training_accuracy')\nplt.plot(range(len(accs)),val_accs, label = 'Validation_accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loss Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"accs = h.history['loss']\nval_accs = h.history['val_loss']\n\nplt.plot(range(len(accs)),accs, label = 'Training_loss')\nplt.plot(range(len(accs)),val_accs, label = 'Validation_loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}